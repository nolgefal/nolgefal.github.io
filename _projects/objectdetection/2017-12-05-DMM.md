---
layout: page
title: "Scratches and Dent on Car"
description: "detect scratched car"
category: deep-learning
---

*** 

### Đặt vấn đề
**Yêu cầu:**
 Nghiên cứu nhận dạng vết trầy xước, lõm trên xe ô tô.

**Giải pháp:** 
 Sử dụng Convolution Neural Network để đưa về bài toán classification, đánh giá xe có trầy xước hay không.

*** 

### Thu thập dữ liệu

Sử dụng Bing Image Search API để lấy các dữ liệu ảnh theo 2 loại: **Xe bình thường** và **Xe có vết trầy xước-lõm**

Lấy dữ liệu theo hướng search ảnh vì nhiều lý do, số lượng ảnh thu được bị hạn chế theo từng từ khóa, kho dữ liệu, sự trùng lặp. Do đó, ta cần đưa ra nhiều loại từ khóa xoay quanh từng loại và sau thi khi thu được một số lượng lớn dữ liệu, ta cần tiền xử lý, xóa bỏ các trường hợp trùng lặp ảnh.

**Source code:** (Python3)

```python
import os
import http.client, urllib.parse, json, urllib.request
import random

# check your subscription key from M$
subscriptionKey = "a8023918783642b89970a4820d43ed6d"
# key 2: "ec63751ee8744d7fa28c7cb8fc446833"

host = "api.cognitive.microsoft.com"
path = "/bing/v7.0/images/search"

# keywords
term = ["car scratch", "car normal"
        ]

def BingImageSearch(search):
    headers = {'Ocp-Apim-Subscription-Key': subscriptionKey}
    conn = http.client.HTTPSConnection(host)
    query = urllib.parse.quote(search)
    conn.request("GET", path + "?q=" + query + '&count=30', headers=headers)
    response = conn.getresponse()
    # headers = [k + ": " + v for (k, v) in response.getheaders() if k.startswith("BingAPIs-") or k.startswith("X-MSEdge-")]
    return response.read().decode("utf8")

def findAll(term, paths):
    print('Searching images for: ', term)
    result = BingImageSearch(term)
    #print("\nJSON Response:\n")
    tt = json.loads(result)

    for e in tt['value']:        
        print(e['contentUrl'])
        try:
            urllib.request.urlretrieve(str(e['contentUrl']), paths + str(random.randint(0,10000)) + ".jpg")        
        except:
            print("Error at: ", e['contentUrl'])

if len(subscriptionKey) == 32:
    dir0 = "/media/lhlong/01D309ADC81A8610/lhlong/ML/work/self/object detection/Celeb_Face_VN"

    for e in term:

        # create folder to save images
        directory = dir0 + "/" + e + "/"

        # create forder
        if not os.path.exists(directory):
            os.makedirs(directory)

        findAll(e, directory)

else:
    print("Invalid Bing Search API subscription key!")
    print("Please paste yours into the source code.")
```

**Kết quả:**
Lấy được 135 ảnh xe trầy xước và 135 ảnh xe bình thường. [Data scratched 270 images](https://drive.google.com/file/d/1_a0M623YidDuGsVUPh0VzX31vskAlKhs/view)

**Đánh giá:**
Dữ liệu đầu vào quá ít, không thể sử dụng CNN theo cách thông thường.
Ta sẽ thử áp dụng kỹ thuật **Transfer Learning** cho tập dữ liệu này.

### Xây dựng mô hình

Sử dụng VGG16, Keras để Transfer Learning. 
Ưu điểm: Nhanh, đơn giản.

```python
# import library
from keras import applications
from keras.preprocessing.image import ImageDataGenerator
from keras import optimizers
from keras.models import Sequential, Model 
from keras.layers import Dropout, Flatten, Dense, GlobalAveragePooling2D
from keras import backend as k 
from keras.callbacks import ModelCheckpoint, LearningRateScheduler, TensorBoard, EarlyStopping

img_width, img_height = 150, 150

# load data set: 200 images train and 70 image test
train_data_dir = '/media/lhlong/01D309ADC81A8610/lhlong/ML/work/self/object detection/UsedCars/scratch/train'
validation_data_dir = '/media/lhlong/01D309ADC81A8610/lhlong/ML/work/self/object detection/UsedCars/scratch/validation'
nb_train_samples = 100
nb_validation_samples = 35
epochs = 100
batch_size = 16 

model = applications.VGG16(weights = "imagenet", include_top=False, input_shape = (img_width, img_height, 3))
# model.summary()

# freezing the first 5 layers.
for layer in model.layers[:5]:
    layer.trainable = False

# adding custom Layers 
x = model.output
x = Flatten()(x)
car  = Dense(256, activation="relu")(x)
car = Dropout(0.5)(car)
prediction_car = Dense(2, activation="softmax")(car)

# creating the final model with multi-output
model_final = Model(input = model.input, outputs = prediction_car)

# compile the model 
model_final.compile(loss = "categorical_crossentropy", 
                    optimizer = optimizers.SGD(lr=0.0001, momentum=0.9), # learning_rate = 0.0001
                    metrics=["accuracy"])

# Initiate the train - valid - test generators with data Augumentation 
train_datagen = ImageDataGenerator(
    rescale = 1./255,    horizontal_flip = True,
    fill_mode = "nearest",    zoom_range = 0.3,
    width_shift_range = 0.3,    height_shift_range=0.3,    rotation_range=30)

valid_datagen = ImageDataGenerator(
    rescale = 1./255,    horizontal_flip = True,
    fill_mode = "nearest",    zoom_range = 0.3,
    width_shift_range = 0.3,    height_shift_range=0.3,    rotation_range=30)

train_generator = train_datagen.flow_from_directory(
    train_data_dir,
    target_size = (img_height, img_width),
    batch_size = batch_size, 
    class_mode = "categorical")

validation_generator = valid_datagen.flow_from_directory(
    validation_data_dir,
    target_size = (img_height, img_width),
    class_mode = "categorical")

history = model_final.fit_generator(
        train_generator,
        steps_per_epoch= (nb_train_samples ) // batch_size,
        epochs=epochs,
        validation_data=validation_generator,
        validation_steps= (nb_validation_samples ) // batch_size)

# save model
VGG_PATH = 'scratch_detect_model_12_04.h5'
model_final.save(VGG_PATH)

# load model
model2 = load_model('scratch_detect_model_12_04.h5')
```

Hiển thị kết quả của model:

```python
print(history.history.keys())

# accuracy
plt.plot(history.history['acc'])
plt.plot(history.history['val_acc'])
plt.title('model accuracy')
plt.ylabel('accuracy')
plt.xlabel('epoch')
plt.legend(['train', 'validation'], loc='upper right')
plt.show()

# loss
plt.plot(history.history['loss'])
plt.plot(history.history['val_loss'])
plt.title('model loss')
plt.ylabel('loss')
plt.xlabel('epoch')
plt.legend(['train', 'validation'], loc='upper right')
plt.show()
```

**Test model**

```python
from keras.preprocessing import image
from keras.applications.resnet50 import preprocess_input, decode_predictions
from matplotlib.pyplot import imshow
import numpy as np
from keras.models import load_model


img_path = '/media/lhlong/01D309ADC81A8610/lhlong/ML/work/self/object detection/UsedCars/car_scratch_image/7.jpg'
img = image.load_img(img_path, target_size=(150, 150))
imshow(img)

x1 = image.img_to_array(img)
x1 = np.expand_dims(x1, axis=0)
images = np.vstack([x1])
classes = model2.predict(images)

if classes[0][0] > 0.5: #1e-10:
    print("Normal")
else:
    print("Scratch")
    
print classes

```

**Kết quả:**
Model đang bị lỗi overfitting.

![alt text](https://raw.githubusercontent.com/lhlong/lhlong.github.io/master/public/img/dmm_overfit.png "DMM Overfitting")

**Giải pháp**
- Tăng lượng dữ liệu input 
- Update lại mô hình

**P/S**: Tăng dữ liệu đầu vào lên 488 ảnh nhưng kết quả cũng chẳng khá hơn. Input có quá nhiều feature (high variance) khiến mô hình overfitting và không thể hội tụ. Giải pháp Transfer Learning trên tập dữ liệu này không thể thực hiện được. 
**Cần phải tăng dữ liệu đầu vào, cỡ 5000 ảnh cho mỗi loại.**


